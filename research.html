<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Ilma</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/970f8bb9a8e1853b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/970f8bb9a8e1853b.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-114634acb84f8baa.js" defer=""></script><script src="/_next/static/chunks/main-1271fe64a3a0ea8e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-b95cc355b8d1cb1f.js" defer=""></script><script src="/_next/static/chunks/pages/research-12cff339dad964b8.js" defer=""></script><script src="/_next/static/TYPiTePS20W2DrWUcmoNk/_buildManifest.js" defer=""></script><script src="/_next/static/TYPiTePS20W2DrWUcmoNk/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="flex h-screen w-screen flex-col items-center"><header class="flex w-full flex-none justify-center bg-gradient-to-b from-[#ff8100] to-[#ffdc00]"><div class="flex w-[800px] flex-row justify-around"><nav class="flex w-full flex-col items-center justify-center p-4 sm:flex-row sm:justify-between"><div class="hover:text-[#007acc]"><a href="/"><h1 class="text-3xl font-bold">Ilma</h1></a></div><ul class="mt-2 flex sm:mt-0"><li class="mx-3 hover:text-[#007acc]"><a href="/team">Team</a></li><li class="mx-3 hover:text-[#007acc]"><a href="/research">Research</a></li><li class="mx-3 hover:text-[#007acc]"><a href="/news">News</a></li></ul></nav></div></header><main class="m-5 max-w-[800px] flex-1 text-lg"><section><div class="flex justify-center"><img alt="research team" src="/images/team.jpg" width="674" height="337" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></div><h1 class="my-4 text-3xl font-bold">Publications</h1></section><section><p class="my-3"><h2 class="text-2xl font-bold"><a href="https://doi.org/10.1145/3463944.3469269">Multimodal Virtual Avatars for Investigative Interviews with Children</a></h2></p><p class="my-3">In this article, we present our ongoing work in the field of training police officers who conduct interviews with abused children. The objectives in this context are to protect vulnerable children from abuse, facilitate prosecution of offenders, and ensure that innocent adults are not accused of criminal acts. There is therefore a need for more data that can be used for improved interviewer training to equip police with the skills to conduct high-quality interviews. To support this important task, we propose to research a training program that utilizes different system components and multimodal data from the field of artificial intelligence such as chatbots, generation of visual content, text-to-speech, and speech-to-text. This program will be able to generate an almost unlimited amount of interview and also training data. The goal of combining all these different technologies and datatypes is to create an immersive and interactive child avatar that responds in a realistic way, to help to support the training of police interviewers, but can also produce synthetic data of interview situations that can be used to solve different problems in the same domain.</p><p class="my-3"><h2 class="text-2xl font-bold"> <a href="https://doi.org/10.1145/3534085.3534340">Towards an AI-driven talking avatar in virtual reality for investigative interviews of children</a></h2></p><p class="my-3">Artificial intelligence (AI) and gaming systems have advanced to the stage where the current models and technologies can be used to address real-world problems. The development of such systems comes with different challenges, e.g., most of them related to system performance, complexity and user testing. Using a virtual reality (VR) environment, we have designed and developed a game-like system aiming to mimic an abused child that can help to assist police and child protection service (CPS) personnel in interview training of maltreated children. Current research in this area points to the poor quality of conducted interviews, and emphasises the need for better training methods. Information obtained in these interviews is the core piece of evidence in the prosecution process. We utilised advanced dialogue models, talking visual avatars, and VR to build a virtual child avatar that can interact with users. We discuss our proposed architecture and the performance of the developed child avatar prototype, and we present the results from the user study conducted with CPS personnel. The user study investigates the users&#x27; perceived quality of experience (QoE) and their learning effects. Our study confirms that such a gaming system can increase the knowledge and skills of the users. We also benchmark and discuss the system performance aspects of the child avatar. Our results show that the proposed prototype works well in practice and is well received by the interview experts.</p><p class="my-3"><h2 class="text-2xl font-bold"><a href="https://doi.org/10.1016/j.chiabu.2022.105685">An overview of mock interviews as a training tool for interviewers of children</a></h2></p><p class="my-3">Mock (simulated) interviews can be used as a safe context for trainee interviewers to learn and practice questioning skills. When mock interviews are designed to reflect the body of scientific evidence on how questioning skills are best learned, research has demonstrated that interviewers acquire relevant and enduring skills. Despite the importance of this exercise in learning interview skill and its prevalence as a learning tool in other fields such as medicine and allied health, there has been relatively little discussion about mock interviews from an educational perspective in investigative interview training. This paper addresses that gap by providing the first comprehensive overview of the way mock interviews have been used in training interviewers of children. We describe the research that supports their utility, and the various ways they can be implemented in training: providing insight to learners; allowing opportunities for practice, feedback, and discussion; and as a standardized way to assess skill change over time. The paper also includes an overview of the cutting-edge use of avatars in mock interviews to enhance efficiency, provide unique learning experiences, and ultimately reduce training costs. We explain why avatars may be particularly useful in basic training, freeing up human trainers to facilitate mock interviews around advanced topics and discussion.</p><p class="my-3"><h2 class="text-2xl font-bold"> <a href="https://doi.org/10.3390/bdcc6020062">Synthesizing a Talking Child Avatar to Train Interviewers Working with Maltreated Children</a></h2></p><p class="my-3">When responding to allegations of child sexual, physical, and psychological abuse, Child Protection Service (CPS) workers and police personnel need to elicit detailed and accurate accounts of the abuse to assist in decision-making and prosecution. Current research emphasizes the importance of the interviewer’s ability to follow empirically based guidelines. In doing so, it is essential to implement economical and scientific training courses for interviewers. Due to recent advances in artificial intelligence, we propose to generate a realistic and interactive child avatar, aiming to mimic a child. Our ongoing research involves the integration and interaction of different components with each other, including how to handle the language, auditory, emotional, and visual components of the avatar. This paper presents three subjective studies that investigate and compare various state-of-the-art methods for implementing multiple aspects of the child avatar. The first user study evaluates the whole system and shows that the system is well received by the expert and highlights the importance of its realism. The second user study investigates the emotional component and how it can be integrated with video and audio, and the third user study investigates realism in the auditory and visual components of the avatar created by different methods. The insights and feedback from these studies have contributed to the refined and improved architecture of the child avatar system which we present here</p><p class="my-3"><h2 class="text-2xl font-bold"><a href="https://doi.org/10.1145/3512731.3534209">Is More Realistic Better? A Comparison of Game Engine and GAN-based Avatars for Investigative Interviews of Children</a></h2></p><p class="my-3">The success of investigative interviews with maltreated children is often defined by the interviewer&#x27;s ability to elicit a reliable and coherent account of the alleged incident from the child. Research shows that a child avatar mimicking a maltreated child can improve interviewers&#x27; performance in conducting these interviews. The realism of such a child avatar is considered one of the most critical factors. Based on this, the current study aims to generate realistic child avatars in real-time that utilize multimodal data and different components from artificial intelligence. This paper discusses the subjective findings of a study of two types of child avatar videos; animated avatars created using the Unity game engine and photorealism talking-head avatars using Generative adversarial networks (GANs). The results show that although the state-of-the-art GAN-generated avatars are significantly more realistic, they do not necessarily create a better experience, as most of the participants prefer talking to animated avatars.</p></section></main><footer class="flex w-full flex-col items-center bg-gradient-to-b from-[#ff8100] to-[#ffdc00] py-4"><div class="flex w-[300px] items-center justify-around"><a href="https://www.oslomet.no/"><img alt="Oslo-met logo" src="/images/logo.png" width="100" height="70" decoding="async" data-nimg="1" class="w-[100px]" loading="lazy" style="color:transparent"/></a><a href="https://www.simulamet.no/"><img alt="simula-logo" src="/images/simula-logo.png" width="100" height="25" decoding="async" data-nimg="1" class="w-[100px]" loading="lazy" style="color:transparent"/></a></div><div><span>Copyright © 2023</span></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/research","query":{},"buildId":"TYPiTePS20W2DrWUcmoNk","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>